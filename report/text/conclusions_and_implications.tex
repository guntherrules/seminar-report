\section{Conclusions and Implications}
%this section summarizes the work and explain the main implications of the results (what have changed now that we know what we know? how could this influence future research?)
From the high performance of the latest GPT-3 model up to GPT-4 on false-belief tasks designed for young children it can be concluded that future LLMs will likely be able to solve more complex ToM tasks. The spontaneous emergence of ToM in LLMs is presented as a possible reason for the high performance of GPT-3.5 and GPT-4 in these tasks, since ToM is not deliberately designed into an LLMs architecture. This would mean that a further development of ToM in LLMs and Artificial Intelligence (AI) in general could lead to more sophisticated skills related to ToM like empathy, morals and consciousness, thus greatly improving the collaboration possibilities of AI and humans. \cite{kosinski}

Another possible implication according to Kosinski is the necessary reevaluation of ToM as it is currently understood and the research related to it. LLMs might rely on unknown language patterns to solve ToM tests, only appearing to have actually learned the ability like a human would in artificial systems.\cite{kosinski}

Thirdly, it is suggested that the presented results account for the benefits of combining artificial intelligence and psychology to not only understand AI better but also gather information about human psychology by analysing the behaviour of AI. \cite{kosinski}